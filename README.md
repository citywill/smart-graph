# GraphRAG智能问答系统

这是一款基于图数据库和向量检索的智能问答系统，支持文档管理和智能对话功能。系统使用Neo4j作为图数据库，Streamlit作为前端框架，结合大语言模型实现基于知识图谱的智能问答。

## 功能特点

### 文档管理

- **文档上传**：支持上传txt、md格式的文本文档
- **文档分块**：自定义分隔符和块大小，智能分割文档
- **文档检索**：按标题搜索文档，支持分页查看
- **文档操作**：查看、下载和删除文档
- **元数据查看**：显示文档标题、上传时间、大小、摘要等信息

### 智能对话

- **基于图谱的问答**：结合文档内容和知识图谱，提供智能问答功能
- **知识图谱可视化**：可视化展示与问题相关的知识图谱，支持放大、缩小、拖拽等交互操作
- **实体识别**：自动从文档中提取实体，构建知识图谱
- **向量检索**：使用BGE M3向量模型进行高效语义检索

## 技术栈

- **开发语言**：Python 3.10
- **前端框架**：Streamlit
- **智能体框架**：LangChain
- **数据库**：Neo4j 5.27.0
- **大模型调用**：兼容OpenAI的API接口
- **向量模型**：BGE M3，基于Ollama的API

## 目录结构

```
.
├── app.py                     # 应用入口
├── pages                      # 页面文件
│   ├── doc_manage.py          # 文档管理页面
│   └── chat.py                # 智能对话页面
├── services                   # 服务层
│   ├── doc_service.py         # 文档处理服务
│   └── rag_service.py         # RAG问答服务
├── utils                      # 工具类
│   ├── neo4j_utils.py         # Neo4j数据库工具类
│   ├── llm_utils.py           # 大模型工具类
│   └── txt_utils.py           # 文本处理工具类
├── uploads                    # 上传文件存储目录
├── prompts.py                 # 提示词模板
├── .env                       # 环境变量配置
├── requirements.txt           # 项目依赖
└── README.md                  # 项目说明
```

## 运行方法

### 1. 环境准备

确保安装了Python 3.10，并启动了Neo4j数据库和Ollama服务。

### 2. 安装依赖

```bash
pip install -r requirements.txt
```

### 3. 配置环境变量

编辑`.env`文件，设置以下配置：
- Neo4j数据库连接信息
- 大模型API密钥和基础URL
- 向量模型配置

### 4. 启动应用

```bash
streamlit run app.py
```

### 5. 访问应用

打开浏览器访问：http://localhost:8501

## 使用流程

1. **文档管理**：
   - 上传文档：选择txt或md格式的文件，设置分块参数，点击上传
   - 查看文档：在文档列表中查看已上传的文档信息和内容
   - 下载/删除：对已上传的文档进行下载或删除操作

2. **智能对话**：
   - 输入问题：在对话框中输入要咨询的问题
   - 获取回答：系统自动检索相关文档块并生成回答
   - 查看知识图谱：如果问题与知识图谱相关，可以查看并交互式操作知识图谱

## 注意事项

- 首次使用前需要先上传一些文档，以便系统可以回答相关问题
- 确保Neo4j数据库和Ollama服务正常运行
- 大文件处理可能需要较长时间，请耐心等待
- 实体识别和知识图谱构建基于大模型，效果受模型质量影响
